{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***notebook này tập trung vào việc áp dụng kĩ thuật Stacked Generalization để nâng cao độ chính xác mô hình***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***references:***\n",
    "- https://viblo.asia/p/lam-chu-stacking-ensemble-learning-Az45b0A6ZxY\n",
    "\n",
    "***nội dung:***\n",
    "\n",
    "0. báo cáo công việc và kết quả\n",
    "1. Basic stacking Ensemble Learning\n",
    "2. Stacking với Cross-Validation\n",
    "3. Multi-levels Stacking\n",
    "4. voting classifier\n",
    "5. Weighted Average Ensemble\n",
    "6. Blending Ensemble\n",
    "7. ngoài lề: kĩ thuật ensemble trong bài toán regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. báo cáo công việc và kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- các phướng pháp stacking generalization techniques là những thuật toán machine learning mạnh mẽ, trong notebook này tập trung ứng dụng các kĩ kĩ thuật stacking và các biến thể mạnh mẽ của nó để cải thiện hiệu suất mô hình trên bộ dữ liệu cũ\n",
    "\n",
    "\n",
    "1. ứng dụng các kĩ thuật staking ensemble learning đơn giản\n",
    "    - kĩ thuật stacking cơ bản:\n",
    "        + sử dụng LogisticRegression, DecisionTreeClassifier, SVC, RandomForestClassifier để làm mô hình cơ sở (base models)\n",
    "        + sử dụng LogisticRegression làm mô hình ảo (meta model) để phân loại đầu ra\n",
    "\n",
    "        => kết quả: độ chính xác có cải thiện (tăng 6% so với kết quả trước đây đối với mô hình RF)\n",
    "\n",
    "2. kĩ thuật stacking với cross-validation\n",
    "    - sử dụng kĩ thuật stacking với cross-validation để giảm thiểu overfiting trên phương pháp 1:\n",
    "        + cross-validation với 5-fold\n",
    "        + base models: DecisionTreeClassifier, SVC, RandomForestClassifier\n",
    "        + meta model: LogisticRegression\n",
    "\n",
    "        => kết quả: độ chính xác cải thiện (tăng 6% so với kết quả trước đây đối với mô hình RF, không tăng so với phương pháp 1)\n",
    "\n",
    "3. kĩ thuật multi-levels stacking\n",
    "    - phát triển từ phương pháp 2 với số lượng tầng meta model tăng lên (từ 1 tăng lên 2)\n",
    "        + base models lv1:DecisionTreeClassifier, SVC, RandomForestClassifier\n",
    "        + meta models với 2 levels: đều dung LogisticRegression\n",
    "        + base models lv2: level1_stacking, RandomForestClassifier, \n",
    "    \n",
    "\n",
    "        => độ chính xác tăng so với phương pháp truyền thống trước đây, tăng không đáng kể so với phương pháp 2\n",
    "\n",
    "4. kĩ thuật voting classifier\n",
    "    - phương pháp: sử dụng hard voting (dựa trên số lượng dự đoán đầu ra) và soft voting (dựa trên xác suất dự đoán đầu ra)\n",
    "    - phương pháp hard-voting:\n",
    "        + base models: DecisionTreeClassifier, SVC, RandomForestClassifier\n",
    "        + voting: hard\n",
    "\n",
    "        => kết quả: độ chính xác tăng đáng kể (đạt 84%, cao nhất từ trước tới nay, tăng trung bình so với các thuật toán khác là 5%, tăng nhiều nhất so với kfold là 9%, tăng ít nhất là 2% so với mô hình catboost)\n",
    "        \n",
    "    - phương pháp soft-voting:\n",
    "        + base models: DecisionTreeClassifier, SVC, RandomForestClassifier\n",
    "        + voting: soft\n",
    "   \n",
    "        => kết quả: độ chính xác tăng khong đáng kể so với các phương pháp cũ, đạt 81%\n",
    "\n",
    "5. kĩ thuật weighted average ensemble\n",
    "    - các base models được sử dụng: XGB_pred + KNN_pred + MLPC_pred + DecisionTree_pred + RandomForest_pred\n",
    "    - giả định 1: các mô hình quan trọng như nhau\n",
    "        + độ chính xác tăng\n",
    "    - giả đinhk 2: mỗi mô hình có trọng số riêng (tầm quan trọng khác nhau)\n",
    "        + độ chính xác tăng\n",
    "\n",
    "6. kĩ thuật blending ensemble\n",
    "    - blending đối với hard-voting:\n",
    "        + base models: LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVC, GaussianNB\n",
    "        + độ chính xác tăng đáng kể: đạt 83%\n",
    "    -blending đối với soft-voting:\n",
    "        + base models: LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVC, GaussianNB\n",
    "        + độ chính xác tăng ít/ không tăng đối với các mô hình trước đây: đạt 81%\n",
    "\n",
    "7. tổng kết\n",
    "    - đạt được:\n",
    "        + sử dụng da dạng các phiên bản và biến thể của stacking generalization\n",
    "        + cải thiện được độ chính xác trên tập dữ liệu cũ\n",
    "\n",
    "    - chưa đạt được:\n",
    "        + tổng quan kết quả vẫn còn cần cải thiện thêm nữa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic stacking Ensemble Learning\n",
    "\n",
    "***ý tưởng cơ bản:***\n",
    "- ý tưởng cơ bản của thuật toán này là thay vì dùng một mô hình machine learning đơn giản thì ta kết hợp các mô hình machine learning khác lại để có được dự đoán mạnh hơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:/IAD/INTERN/01_diabetes/data/diabetes.csv\")\n",
    "# df.head()\n",
    "# print(len(df.columns))\n",
    "# print(y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8)\n",
      "(614,)\n",
      "(154, 8)\n",
      "(154,)\n"
     ]
    }
   ],
   "source": [
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracu = 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# create base models\n",
    "base_model = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "\n",
    "# create meta model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "\n",
    "# create stacking model\n",
    "stacking_model = StackingClassifier(estimators=base_model, final_estimator=meta_model)\n",
    "\n",
    "\n",
    "stacking_model.fit(x_train, y_train)\n",
    "y_pred = stacking_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracu = {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Stacking với Cross-Validation\n",
    "\n",
    "***điểm chú ý:***\n",
    "- tạo ra nhiều test set và kết hợp chúng lại\n",
    "\n",
    "***cơ chế:***\n",
    "- chia tập dữ liệu thành k tập (k-fold)\n",
    "- đối với mỗi mô hình, dùng k-1 tập để huấn luyện, 1 tập còn lại để kiểm thử mô hình\n",
    "- dự đoán 1 phần còn lại đó và cả trên test set\n",
    "- tổng hợp các kết quả chạy được (bao gồm cả kết quả test trên 1 fold và cả test set trên các mô hình)\n",
    "- nếu bài toán cần giải quyết là regression thì ta tính mean còn class thì ta sử dụng voting để đưa ra kết quả cuối cùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracu = 0.8116883116883117\n"
     ]
    }
   ],
   "source": [
    "# create base models\n",
    "base_model = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "\n",
    "# create meta model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "\n",
    "# create stacking model\n",
    "stacking_model = StackingClassifier(estimators=base_model, final_estimator=meta_model, cv=5) # 5-fold cross-validation\n",
    "\n",
    "\n",
    "stacking_model.fit(x_train, y_train)\n",
    "y_pred = stacking_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracu = {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-levels Stacking\n",
    "\n",
    "***cơ chế:***\n",
    "- sau khi huấn luyện sử dụng phương pháp stacking (based models - level 0 và meta model - level1)\n",
    "- thì thay vì chỉ có 1 lớp meta model thì bây giờ thêm nhiều meta models và các tầng meta models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracyu = 0.8116883116883117\n"
     ]
    }
   ],
   "source": [
    "level1_models = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]\n",
    "level1_meta_model = LogisticRegression()\n",
    "level1_stacking = StackingClassifier(estimators=level1_models, final_estimator=level1_meta_model, cv=5)\n",
    "level1_stacking.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# level 2\n",
    "level2_models = [\n",
    "    ('level1_stacking_model', level1_stacking),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('svm', SVC(probability=True))\n",
    "]\n",
    "level2_stacking_model = LogisticRegression()\n",
    "level2_stacking = StackingClassifier(estimators=level2_models, final_estimator=level2_stacking_model, cv=5)\n",
    "level2_stacking.fit(x_train, y_train)\n",
    "\n",
    "y_pred = level2_stacking.predict(x_test)\n",
    "accuracu = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracyu = {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. voting classifier\n",
    "\n",
    "https://machinelearningmastery.com/voting-ensembles-with-python/\n",
    "\n",
    "***cơ chế:***\n",
    "- sử dụng phương pháp thống kê đơn giản\n",
    "- voting sẽ dử dụng hard-voting được predicted nhiều nhất\n",
    "- hoặc soft-voting được predicted với class có tổng xác suất cao nhất \n",
    "- trong voting, các based models được giả định có độ quan trọng như nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8441558441558441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "base_models = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]   \n",
    "\n",
    "meta_model = VotingClassifier(estimators=base_models)\n",
    "meta_model.fit(x_train, y_train)\n",
    "pred = meta_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'accuracy = {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8376623376623377\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]   \n",
    "\n",
    "meta_model = VotingClassifier(estimators=base_models, voting='hard')\n",
    "meta_model.fit(x_train, y_train)\n",
    "pred = meta_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'accuracy = {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8116883116883117\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('rf', RandomForestClassifier())\n",
    "]   \n",
    "\n",
    "meta_model = VotingClassifier(estimators=base_models, voting='soft')\n",
    "meta_model.fit(x_train, y_train)\n",
    "pred = meta_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'accuracy = {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = knn1, mean = 0.6766404647983596, std = 0.05627723759360064\n",
      "name = knn3, mean = 0.6962292093871042, std = 0.04791392086663333\n",
      "name = knn5, mean = 0.7174698108908635, std = 0.03957102555584292\n",
      "name = knn7, mean = 0.7252620186830714, std = 0.0446881681408015\n",
      "name = knn9, mean = 0.7348086124401915, std = 0.04471529175902817\n",
      "name = hard_voting, mean = 0.718324219640009, std = 0.04931925746433479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOS UC\\AppData\\Local\\Temp\\ipykernel_3156\\1027644249.py:47: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(results, labels=names, showmeans=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_voting():\n",
    "    # define the base models\n",
    "    model = list()\n",
    "    model.append(('knn1', KNeighborsClassifier(n_neighbors=1)))\n",
    "    model.append(('knn3', KNeighborsClassifier(n_neighbors=3)))\n",
    "    model.append(('knn5', KNeighborsClassifier(n_neighbors=5)))\n",
    "    model.append(('knn7', KNeighborsClassifier(n_neighbors=7)))\n",
    "    model.append(('knn9', KNeighborsClassifier(n_neighbors=9)))\n",
    "    # define the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=model, voting='hard')\n",
    "    return ensemble  # Return the ensemble model, not the list of models\n",
    "\n",
    "def get_models():\n",
    "    # get a list of model to evaluate\n",
    "    models = dict()\n",
    "    models['knn1'] = KNeighborsClassifier(n_neighbors=1)\n",
    "    models['knn3'] = KNeighborsClassifier(n_neighbors=3)\n",
    "    models['knn5'] = KNeighborsClassifier(n_neighbors=5)\n",
    "    models['knn7'] = KNeighborsClassifier(n_neighbors=7)\n",
    "    models['knn9'] = KNeighborsClassifier(n_neighbors=9)\n",
    "    models['hard_voting'] = get_voting()\n",
    "    return models\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# Assuming X and y are your feature matrix and target vector respectively\n",
    "# X, y = your_data_loading_function()\n",
    "\n",
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, x, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print(f'name = {name}, mean = {mean(scores)}, std = {std(scores)}')\n",
    "\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Weighted Average Ensemble\n",
    "https://medium.com/analytics-vidhya/simple-weighted-average-ensemble-machine-learning-777824852426\n",
    "\n",
    "***cơ chế:***\n",
    "- sử dụng một tập hợp các based models để thực hiện dự đoán\n",
    "- dựa trên cơ chế là đánh giá các trọng số của based models (ví dụ dựa trên accuracy, performence...)\n",
    "- đầu ra là từng trọng số của mô hình nhân với predictions của nó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 1 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1\n",
      " 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"The target variable is binary, either 0 (didn’t purchase) or 1 (Quote converted).\"\"\"\n",
    "\n",
    "# Decision Tree\n",
    "DecisionTree = DecisionTreeClassifier()\n",
    "DecisionTree.fit(x_train, y_train)\n",
    "DecisionTree_pred = DecisionTree.predict(x_test)\n",
    "print(DecisionTree_pred)\n",
    "# DecisionTreePrediction = pd.DataFrame(\n",
    "#     {'QuoteNumber': y_test},\n",
    "#     {'QuoteConversion_Flag': DecisionTree_pred}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "DecisionTree = DecisionTreeClassifier()\n",
    "DecisionTree.fit(x_train, y_train)\n",
    "DecisionTree_pred = DecisionTree.predict(x_test)\n",
    "DecisionTreePrediction = pd.DataFrame(\n",
    "    {'QuoteNumber': y_test,\n",
    "    'QuoteConversion_Flag': DecisionTree_pred}\n",
    ")\n",
    "DecisionTreePrediction.to_csv('DecisionTreePrediction.csv', index=False)\n",
    "\n",
    "\n",
    "# KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors=2)\n",
    "KNN.fit(x_train, y_train)\n",
    "KNN_pred = KNN.predict(x_test)\n",
    "KNNPrediction = pd.DataFrame(\n",
    "    {'QuoteNumber': y_test,\n",
    "    'QuoteConversion_Flag': KNN_pred}\n",
    ")\n",
    "KNNPrediction.to_csv('KNNPrediction.csv', index=False)\n",
    "\n",
    "\n",
    "# MLPC\n",
    "MLPC = MLPClassifier(random_state=1, max_iter=100)\n",
    "MLPC.fit(x_train, y_train)\n",
    "MLPC_pred = MLPC.predict(x_test)\n",
    "MLPCPrediction = pd.DataFrame(\n",
    "    {'QuoteNumber': y_test,\n",
    "    'QuoteConversion_Flag': MLPC_pred}\n",
    ")\n",
    "MLPCPrediction.to_csv('MLPCPrediction.csv', index=False)\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "RandomForest = RandomForestClassifier()\n",
    "RandomForest.fit(x_train, y_train)\n",
    "RandomForest_pred = RandomForest.predict(x_test)\n",
    "RandomForestPrediction = pd.DataFrame(\n",
    "    {'QuoteNumber': y_test,\n",
    "    'QuoteConversion_Flag': RandomForest_pred}\n",
    ")\n",
    "RandomForestPrediction.to_csv('RandomForestPrediction.csv', index=False)\n",
    "\n",
    "\n",
    "# XGB classifier\n",
    "XGB = XGBClassifier()\n",
    "XGB.fit(x_train, y_train)\n",
    "XGB_pred = XGB.predict(x_test)\n",
    "XGBPrediction = pd.DataFrame(\n",
    "    {'QuoteNumber': y_test,\n",
    "    'QuoteConversion_Flag': XGB_pred}\n",
    ")\n",
    "XGBPrediction.to_csv('XGBPrediction.csv', index=False)\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# average weights\n",
    "average_pred = (XGB_pred + KNN_pred + MLPC_pred + DecisionTree_pred + RandomForest_pred) / 5\n",
    "\n",
    "# make submission table\n",
    "FiveModelAveragePrediction = pd.DataFrame(\n",
    "    {'QuoteNumber': y_test,\n",
    "     'QuoteConversion_Flag': average_pred}\n",
    ")\n",
    "FiveModelAveragePrediction.to_csv('FiveModelAveragePrediction.csv', index=False)\n",
    "\n",
    "# weighted average\n",
    "weighted_average = (0.3*XGB_pred + 0.2*KNN_pred + 0.2*MLPC_pred + 0.15*DecisionTree_pred + 0.15*RandomForest_pred)\n",
    "\n",
    "# make submission table\n",
    "WeightedAveragePrediction = pd.DataFrame(\n",
    "    {'QouteNumber': y_test,\n",
    "     'QuoteConversion_Flag': weighted_average}\n",
    ")\n",
    "WeightedAveragePrediction.to_csv('WeightedAveragePrediction.csv', index=False)\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Blending Ensemble\n",
    "https://machinelearningmastery.com/blending-ensemble-machine-learning-with-python/\n",
    "\n",
    "***tổng quan:***\n",
    "- chia dataset thành 2 phần (sebset-1 và subset2)\n",
    "- dùng subset-1 để huấn luyện các based models (KNN, Linear...)\n",
    "- dùng subset-2 để thực hiện predict trên các based models đó ta có được predictions của subset-2\n",
    "- từ các kết quả của predictions, ta dùng nó làm dữ liệu huấn luyện cho blender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8311688311688312\n"
     ]
    }
   ],
   "source": [
    "# FOR CLASSIFICATION\n",
    "\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr', LogisticRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeClassifier()))\n",
    "    models.append(('svm', SVC()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, x_train, y_train, x_test, y_test):\n",
    "    # fit all models on the training dataset\n",
    "    meta_x = list()\n",
    "    for name, model in models:\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        pred = pred.reshape(len(pred), 1)\n",
    "        meta_x.append(pred)\n",
    "\n",
    "    meta_x = hstack(meta_x)\n",
    "    blender = LogisticRegression()\n",
    "    blender.fit(meta_x, y_test)\n",
    "    return blender\n",
    "\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, x_test):\n",
    "    meta_x = list()\n",
    "    for name, model in models:\n",
    "        pred = model.predict(x_test)\n",
    "        pred = pred.reshape(len(pred), 1)\n",
    "        meta_x.append(pred)\n",
    "\n",
    "    meta_x = hstack(meta_x)\n",
    "    return blender.predict(meta_x)\n",
    "\n",
    "\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, x_train, y_train, x_test, y_test)\n",
    "pred = predict_ensemble(models, blender, x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***bleding ensemble with soft voting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr', LogisticRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeClassifier()))\n",
    "    models.append(('svm', SVC(probability=True)))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "\n",
    "def fit_ensemble(models, x_train, y_train, x_test, y_test):\n",
    "    meta_x = list()\n",
    "    for name, model in models:\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict_proba(x_test)\n",
    "        meta_x.append(pred)  \n",
    "\n",
    "    meta_x = hstack(meta_x)\n",
    "    blender = LogisticRegression()\n",
    "    blender.fit(meta_x, y_test)\n",
    "    return blender\n",
    "\n",
    "\n",
    "def predict_ensemble(model, blender, x_test):\n",
    "    meta_x = list()\n",
    "    for name, model in models:\n",
    "        pred = model.predict_proba(x_test)\n",
    "        meta_x.append(pred)\n",
    "    \n",
    "    meta_x = hstack(meta_x)\n",
    "    return blender.predict_proba(meta_x)\n",
    "\n",
    "\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, x_train, y_train, x_test, y_test)\n",
    "pred = predict_ensemble(models, blender, x_test)\n",
    "# print(pred)\n",
    "pred_class = [np.argmax(i) for i in pred]\n",
    "# print(pred_class)\n",
    "accuracy = accuracy_score(y_test, pred_class)\n",
    "print(f'accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***blending ensemble for regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate blending ensemble for regression\n",
    "from numpy import hstack\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      148\n",
      "1       85\n",
      "2      183\n",
      "3       89\n",
      "4      137\n",
      "      ... \n",
      "763    101\n",
      "764    122\n",
      "765    121\n",
      "766    126\n",
      "767     93\n",
      "Name: Glucose, Length: 768, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x = df['Glucose']\n",
    "print(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ngoài lề: kĩ thuật ensemble trong bài toán regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR REGRESSION\n",
    "\n",
    "def get_dataset():\n",
    "\tx, y = make_regression(n_samples=10000, n_features=20, n_informative=10, noise=0.3, random_state=7)\n",
    "\treturn x, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr', LinearRegression()))\n",
    "    models.append(('knn', KNeighborsRegressor()))\n",
    "    models.append(('cart', DecisionTreeRegressor()))\n",
    "    models.append(('svm', SVR()))\n",
    "    return models\n",
    "\n",
    "\n",
    "def fit_ensemble(models, x_train, y_train, x_test, y_test):\n",
    "    meta_x = list()\n",
    "    for name, model in models:\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        meta_x.append(pred)\n",
    "        pred = pred.reshape(len(pred), 1)\n",
    "    \n",
    "    meta_x = hstack(meta_x)\n",
    "    blender = LinearRegression()\n",
    "    blender.fit(pred, y_test)\n",
    "    return blender\n",
    "\n",
    "\n",
    "def predict_ensemble(model, blender, x_test):\n",
    "    meta_x = list()\n",
    "    for name, model in models:\n",
    "        pred = model.predict(x_test)\n",
    "        pred = pred.reshape(len(pred), 1)\n",
    "        meta_x.append(pred)\n",
    "\n",
    "    meta_x = hstack(meta_x)\n",
    "    return blender.predict(meta_x)\n",
    "\n",
    "\n",
    "x, y = get_dataset()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, x_train, y_train, x_test, y_test)\n",
    "pred = predict_ensemble(models, blender, x_test)\n",
    "# print(pred)\n",
    "accuracy = mean_absolute_error(y_test, pred)\n",
    "print(f'accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6700, 20), Val: (3300, 20)\n",
      "Predicted: 359.986\n"
     ]
    }
   ],
   "source": [
    "# example of making a prediction with a blending ensemble for regression\n",
    "from numpy import hstack\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=10000, n_features=20, n_informative=10, noise=0.3, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "\tmodels = list()\n",
    "\tmodels.append(('lr', LinearRegression()))\n",
    "\tmodels.append(('knn', KNeighborsRegressor()))\n",
    "\tmodels.append(('cart', DecisionTreeRegressor()))\n",
    "\tmodels.append(('svm', SVR()))\n",
    "\treturn models\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "\t# fit all models on the training set and predict on hold out set\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# fit in training set\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\t# predict on hold out set\n",
    "\t\tyhat = model.predict(X_val)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store predictions as input for blending\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# define blending model\n",
    "\tblender = LinearRegression()\n",
    "\t# fit on predictions from base models\n",
    "\tblender.fit(meta_X, y_val)\n",
    "\treturn blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "\t# make predictions with base models\n",
    "\tmeta_X = list()\n",
    "\tfor _, model in models:\n",
    "\t\t# predict with base model\n",
    "\t\tyhat = model.predict(X_test)\n",
    "\t\t# reshape predictions into a matrix with one column\n",
    "\t\tyhat = yhat.reshape(len(yhat), 1)\n",
    "\t\t# store prediction\n",
    "\t\tmeta_X.append(yhat)\n",
    "\t# create 2d array from predictions, each set is an input feature\n",
    "\tmeta_X = hstack(meta_X)\n",
    "\t# predict\n",
    "\treturn blender.predict(meta_X)\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Val: %s' % (X_train.shape, X_val.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make a prediction on a new row of data\n",
    "row = [-0.24038754, 0.55423865, -0.48979221, 1.56074459, -1.16007611, 1.10049103, 1.18385406, -1.57344162, 0.97862519, -0.03166643, 1.77099821, 1.98645499, 0.86780193, 2.01534177, 2.51509494, -1.04609004, -0.19428148, -0.05967386, -2.67168985, 1.07182911]\n",
    "yhat = predict_ensemble(models, blender, [row])\n",
    "# summarize prediction\n",
    "print('Predicted: %.3f' % (yhat[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
