{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TỔNG QUAN NỘI DUNG BÁO CÁO***\n",
    "\n",
    "Phần 1. báo cáo lần thứ 1\n",
    "- tìm hiểu đề tài\n",
    "- chọn ra bài báo hay và làm theo\n",
    "- tổng kết kết quả và báo cáo\n",
    "- đưa ra phương hướng phát triển tiếp theo\n",
    "    \n",
    "Phần 2. báo cáo lần thứ 2\n",
    "- dựa vào các phương pháp đề xuất của các thầy, thực hiện thử nghiệm lại trên các phương pháp được đề xuất\n",
    "- báo cáo kết quả cho mỗi phương pháp được đưa ra, các phương pháp đó là:\n",
    "    + xử lí outlier trên dữ liệu hiện tại\n",
    "    + sử dụng kĩ thuật stacked generalization\n",
    "    + ứng dụng GAN khắc phục dữ liệu bị thiếu\n",
    "    + sử dụng transformer tạo thêm các đặc trưng\n",
    "    + ứng dụng phương pháp SMOTE (synthetic minority over-sampling tenique)\n",
    "    + ADASYN để xử lí vấn đề dữ liệu không cân bằng\n",
    "    + phân tích độ nhạy (sénitivity analysis)\n",
    "    + sử dụng bộ dữ liệu khác tương đương với dữ liệu hiện tại\n",
    "\n",
    "Phần 3. báo cáo lần thứ 3\n",
    "- hiện chưa có\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phần 1. Báo cáo lần thứ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mục 1. nêu lên các vấn đề được yêu cầu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Bài báo lựa chọn: \n",
    "    - title: Diabetes prediction model using machine learning techniques\n",
    "\n",
    "    - Link bài báo: https://doi.org/10.1007/s11042-023-16745-4\n",
    "\n",
    "    - Bài báo: diabetes.pdf\n",
    "\n",
    "2. Phương pháp tác giả sử dụng: \n",
    "    - các kĩ thuật học máy (Logistic regression, SVM, Neive Bayes, Random forest) và kĩ thuật học máy tổng hợp tổng hợp (XGBoost, LightGBM, CatBoost, Adaboost và Bagging)\n",
    "    - tác giả trình bày Sự khác nhau của 2 loại phương pháp trên là phương pháp học máy tổng hợp kết hợp các dự đoán từ nhiều người học cơ bản, mang lại dự đoán cuối cùng chính xác\n",
    "\n",
    "3. Bộ dữ liệu:\n",
    "    - lấy từ Kaggle\n",
    "\n",
    "4. Phương pháp đánh giá của bài báo: \n",
    "    - confusion matrix, các phép đo độ nhạy và độ chính xác\n",
    "\n",
    "5. Kết quả: \n",
    "    - CatBoost nổi lên là hiệu quả nhất, có tỷ lệ chính xác ấn tượng là 95,4% so với 94,3% của XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mục 2. báo cáo kết quả thực hiện dựa trên yêu cầu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. đã làm được\n",
    "    - thực hiện training tất cả các mô hình dựa theo đề xuất của tác giả\n",
    "    - đã áp dụng các kĩ thuật được tác giả đề xuất\n",
    "    - kết quả đạt được như sau: Logistic regression (79%), SVM (76%), Naive Bayes (76%), RF (81%), XGBoost (78%), LightGBM (79%), CatBoost (82%), Adaboost (81%), Bagging (82%), RF sử dụng kĩ thuật KFold (75%)\n",
    "\n",
    "\n",
    "2. sự khác nhau giữa bài làm của em và nghiên cứu của tác giả:\n",
    "    - không sử dụng chung một dataset (bộ dataset tác giả cung cấp bị xóa, không tìm thấy trang)\n",
    "    - các tham số có thể khác với tác giả\n",
    "\n",
    "3. Nguyên nhân độ chính xác không như mong đợi: \n",
    "    - bộ data của em có ít dữ liệu (tác giả 5000 mẫu, trong khi data của em chỉ có 768)\n",
    "    - dữ liệu không cân bằng\n",
    "    - sử dụng hết các feature trong bộ dataset, chưa chọn ra feature tốt\n",
    "    - các siêu tham số mô hình có thể chưa giống với tác giả\n",
    "\n",
    "4. hạn chế\n",
    "    - kết quả vẫn còn thấp\n",
    "\n",
    "5. các hướng đề xuất mới (phương hướng trong tương lai)\n",
    "    - áp dụng kĩ thuật stacking model để cải thiện độ chính xác\n",
    "    - áp dụng kĩ thuật super learner để cải thiện độ chính xác\n",
    "    - ứng dụng mô hình tạo sinh GAN để tạo dữ liệu mới, đồng thời fine-tuning lại đầu ra của model để có thể vừa tạo sinh dữ liệu vừa thực hiện phân loại, ngoài ra việc sinh ra dữ liệu mới giống dữ liệu thật giúp khắc phục vấn đề mất cân bằng dữ liệu.\n",
    "    \n",
    "    * (các phương hướng này em tổng hợp từ các bài báo cùng đề tài)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phần 2. báo cáo lần thứ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mục 1. nhắc lại các phương hướng được đề xuất cải tiến\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ xử lí outlier trên dữ liệu hiện tại\n",
    "+ sử dụng kĩ thuật stacked generalization\n",
    "+ ứng dụng GAN khắc phục dữ liệu bị thiếu\n",
    "+ sử dụng transformer tạo thêm các đặc trưng\n",
    "+ ứng dụng phương pháp SMOTE (synthetic minority over-sampling tenique)\n",
    "+ ADASYN để xử lí vấn đề dữ liệu không cân bằng\n",
    "+ phân tích độ nhạy (sénitivity analysis)\n",
    "+ sử dụng bộ dữ liệu khác tương đương với dữ liệu hiện tại"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mục 2. báo cáo kết quả dựa trên phương hướng được đề xuất"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***vấn đề 1. làm việc với các outlier trên dữ liệu hiện tại***\n",
    "\n",
    "1. xử lí dữ liệu với outlier và training lại model\n",
    "    - thay thế outlier bằng trung vị:\n",
    "        + thực hiện thay thế các giá trị outlier không thực tế bằng giá trị trung vị, các outlier ở mức cho phép thì vẫn giữ nguyên\n",
    "        \n",
    "        => kết quả: độ chính xác có tăng nhưng không đáng kể, dữ mean và trung vị của dữ liệu không có sự thay đổi lớn. trung bình độ chính xác tăng dao động từ 1% - 3%, một số mô hình có độ chính xác giảm\n",
    "    \n",
    "    - loại bỏ outlier quá bất thường:\n",
    "        + vẫn giữ các outlier nằm trong khoảng giá trị cho phép của các chỉ số trên thực tế\n",
    "        + loại bỏ các outlier được cho là không thể có (tìm hiểu bên ngoài + hỏi chatGPT)\n",
    "\n",
    "        => kết quả: độ chính xác mô hình tăng rất ít, mean và trung vị nhìn chung thay đổi ít. việc loại bỏ outlier cũng khiến một vài mô hình giảm hiệu suất và độ chính xác. nhìn chung không có sự cải thiện nào về hiệu suất mô hình\n",
    "\n",
    "2. thử nghiệm trên từng feature và training lại model, đưa ra so sánh\n",
    "    - thử nghiệm loại bỏ một vài cột như: \n",
    "        + độ dày da, nhịp tim... và giữ lại các cột quan trọng như chỉ số glucose, insulin... để đánh giá mô hình\n",
    "\n",
    "        => kết quả cũng không có sự cải thiện đáng kể nào, một vài mô hình có dấu hiệu giảm độ chính xác\n",
    "\n",
    "3. training trên một vài feature tốt nhất để so sánh hiệu suất\n",
    "\n",
    "4. tổng kết\n",
    "    - đạt được:\n",
    "        + tìm hiểu được các phương pháp xử lí dữ liệu với outlier\n",
    "        + áp dụng được các phương pháp xử lí với outlier (thay thế bằng trung vị/trung bình, loại bỏ outlier)\n",
    "\n",
    "    - hạn chế:\n",
    "        + chưa có nhiều kinh nghiệm trong việc xử lí dữ liệu, hiểu sâu sắc mỗi tương quan dữ liệu\n",
    "        + độ chính xác không cải thiện nhiều trên các phương pháp được thử nghiệm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***vấn đề 2. sử dụng kĩ thuật stacked generalization để cải thiện độ chính xác của mô hình***\n",
    "\n",
    "- các phướng pháp stacking generalization techniques là những thuật toán machine learning mạnh mẽ, trong notebook này tập trung ứng dụng các kĩ kĩ thuật stacking và các biến thể mạnh mẽ của nó để cải thiện hiệu suất mô hình trên bộ dữ liệu cũ\n",
    "\n",
    "\n",
    "1. ứng dụng các kĩ thuật staking ensemble learning đơn giản\n",
    "    - kĩ thuật stacking cơ bản:\n",
    "        + sử dụng LogisticRegression, DecisionTreeClassifier, SVC, RandomForestClassifier để làm mô hình cơ sở (base models)\n",
    "        + sử dụng LogisticRegression làm mô hình ảo (meta model) để phân loại đầu ra\n",
    "\n",
    "        => kết quả: độ chính xác có cải thiện (tăng 6% so với kết quả trước đây đối với mô hình RF)\n",
    "\n",
    "2. kĩ thuật stacking với cross-validation\n",
    "    - sử dụng kĩ thuật stacking với cross-validation để giảm thiểu overfiting trên phương pháp 1:\n",
    "        + cross-validation với 5-fold\n",
    "        + base models: DecisionTreeClassifier, SVC, RandomForestClassifier\n",
    "        + meta model: LogisticRegression\n",
    "\n",
    "        => kết quả: độ chính xác cải thiện (tăng 6% so với kết quả trước đây đối với mô hình RF, không tăng so với phương pháp 1)\n",
    "\n",
    "3. kĩ thuật multi-levels stacking\n",
    "    - phát triển từ phương pháp 2 với số lượng tầng meta model tăng lên (từ 1 tăng lên 2)\n",
    "        + base models lv1:DecisionTreeClassifier, SVC, RandomForestClassifier\n",
    "        + meta models với 2 levels: đều dung LogisticRegression\n",
    "        + base models lv2: level1_stacking, RandomForestClassifier, SVC\n",
    "\n",
    "        => độ chính xác tăng so với phương pháp truyền thống trước đây, tăng không đáng kể so với phương pháp 2\n",
    "\n",
    "4. kĩ thuật voting classifier\n",
    "    - phương pháp: sử dụng hard voting (dựa trên số lượng dự đoán đầu ra) và soft voting (dựa trên xác suất dự đoán đầu ra)\n",
    "    - phương pháp hard-voting:\n",
    "        + base models: DecisionTreeClassifier, SVC, RandomForestClassifier\n",
    "        + voting: hard\n",
    "\n",
    "        => kết quả: độ chính xác tăng đáng kể (đạt 84%, cao nhất từ trước tới nay, tăng trung bình so với các thuật toán khác là 5%, tăng nhiều nhất so với kfold là 9%, tăng ít nhất là 2% so với mô hình catboost)\n",
    "        \n",
    "    - phương pháp soft-voting:\n",
    "        + base models: DecisionTreeClassifier, SVC, RandomForestClassifier\n",
    "        + voting: soft\n",
    "   \n",
    "        => kết quả: độ chính xác tăng khong đáng kể so với các phương pháp cũ, đạt 81%\n",
    "\n",
    "5. kĩ thuật weighted average ensemble\n",
    "    - các base models được sử dụng: XGB_pred + KNN_pred + MLPC_pred + DecisionTree_pred + RandomForest_pred\n",
    "    - giả định 1: các mô hình quan trọng như nhau\n",
    "        + độ chính xác tăng\n",
    "    - giả đinhk 2: mỗi mô hình có trọng số riêng (tầm quan trọng khác nhau)\n",
    "        + độ chính xác tăng\n",
    "\n",
    "6. kĩ thuật blending ensemble\n",
    "    - blending đối với hard-voting:\n",
    "        + base models: LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVC, GaussianNB\n",
    "        + độ chính xác tăng đáng kể: đạt 83%\n",
    "    -blending đối với soft-voting:\n",
    "        + base models: LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVC, GaussianNB\n",
    "        + độ chính xác tăng ít/ không tăng đối với các mô hình trước đây: đạt 81%\n",
    "\n",
    "7. tổng kết\n",
    "    - đạt được:\n",
    "        + sử dụng da dạng các phiên bản và biến thể của stacking generalization\n",
    "        + cải thiện được độ chính xác trên tập dữ liệu cũ\n",
    "\n",
    "    - chưa đạt được:\n",
    "        + tổng quan kết quả vẫn còn cần cải thiện thêm nữa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***vấn đề 3. ứng dụng GAN tạo ra dữ liệu mới nhằm giải quyết vấn đề thiếu dữ liệu***\n",
    "\n",
    "1. sử dụng mạng ANN để tạo dữ liệu mới\n",
    "    - các dữ liệu mới được tạo ra dựa trên dữ liệu cũ\n",
    "    - số lượng các feature được tạo ra vẫn giữ nguyên (8/8)\n",
    "    - training thử nghiệm trên 5000 và 12000 epochs\n",
    "\n",
    "2. training dữ liệu mới bởi GAN\n",
    "    - không\n",
    "\n",
    "3.kết quả:\n",
    "    - phân phối của dữ liệu sinh ra không giống với thực tế\n",
    "    - ngưỡng của dữ liệu không đa dạng, qúa tập trung vào mức phân phối\n",
    "\n",
    "4. tổng kết\n",
    "    - đạt được:\n",
    "        + áp dụng thành công GAN tạo mới dữ liệu\n",
    "\n",
    "    - chưa đạt được:\n",
    "        + dữ liệu sinh ra không phù hợp để training\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***vấn đề 4. sử dụng mô hình transformer để tạo thêm các đặc trưng mới trên bộ dữ liệu cũ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***vấn đề 5. sử dụng phương pháp smote để giải quyết vấn đề mất cân bằng dữ liệu***\n",
    "\n",
    "smote: Synthetic Minority Over-sampling Technique\n",
    "\n",
    "1.kết quả thực hiện\n",
    "- phương pháp smote được sử dụng thành công trong việc tạo ra dữ liệu mới\n",
    "- độ chính xác có cải thiện nhưng không đáng kể, một số mô hình có độ chính xác giảm so với các phương pháp khác"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***vấn đề 6. sử dụng phương pháp ADASYN để giải quyết vấn đề mất cân bằng dữ liệu***\n",
    "(Adaptive Synthetic Sampling)\n",
    "\n",
    "1. Kết quả thực hiện\n",
    "- thành công áp dụng phương pháp ADASYN\n",
    "- kết quả huấn luyện có tăng nhưng không đáng kể (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***vấn đề 7. kĩ thuật phân tích độ nhạy trên bộ dữ liệu (sensitivity analysis)***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phần 3. Tổng kết nội dung Báo cáo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đạt được\n",
    "- áp dụng nhiều mô hình học học máy khác nhau để dự đoán kết quả thành công\n",
    "- thành công trong việc áp dụng các kĩ thuật khác nhau trong việc cố găng tăng độ chính xác trên bộ dữ liệu hiện tại\n",
    "- một số phương pháp cho kết quả tốt hơn như: StackedGeneralization (staking cơ bản - logistic, decisiontree, SVC, RF..., cross validation, voting - hard voting/soft voting)\n",
    "- hiệu quả độ chính xác tăng thấp nhất 4%, cao nhất 8%\n",
    "- các phương pháp khác còn lại cho kết quả không ổn định bằng phương pháp ban đầu (00_diabetesUsingMachineLearning.ipynb), hoặc kém ổn định hơn.\n",
    "- GAN được áp dụng thành công nhưng phân phối dữ liệu không được tự nhiên, mô hình quá tập trung vào trung vị\n",
    "\n",
    "### Chưa đạt được\n",
    "- vấn đề sử dụng Transformer để tạo các đặc trưng mới\n",
    "- kĩ thuật phân tích độ nhạy vẫn chưa thực hiện được\n",
    "\n",
    "### Khó khăn\n",
    "- chưa làm việc hiểu quả với xử lí ngoại lệ\n",
    "- thực thi và hiểu kết quả trong phân tích độ nhạy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
