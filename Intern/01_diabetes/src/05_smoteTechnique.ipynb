{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***notebook này tập trung vào việc áp dụng kĩ thuật Synthetic Minority Over-sampling Technique (SMOTE) để giải quyết vấn đề mất cân bằng dữ liệu***\n",
    "\n",
    "***references:***\n",
    "- https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/\n",
    "- https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python/\n",
    "- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "- https://www.youtube.com/results?search_query=smote+technique+in+machine+learning\n",
    "\n",
    "***nội dung thực hiện:***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tổng quan về Kỹ thuật SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "**1. Giới thiệu về SMOTE:**\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) là một phương pháp phổ biến để xử lý vấn đề mất cân bằng lớp trong các bộ dữ liệu học máy. Mất cân bằng lớp xảy ra khi một hoặc nhiều lớp có số lượng mẫu ít hơn đáng kể so với các lớp khác, dẫn đến mô hình học máy có xu hướng thiên vị lớp chiếm đa số.\n",
    "\n",
    "**2. Nguyên tắc hoạt động:**\n",
    "\n",
    "SMOTE tạo ra các mẫu tổng hợp từ lớp thiểu số bằng cách sử dụng kỹ thuật nội suy giữa các mẫu hiện có. Thay vì sao chép trực tiếp các mẫu thiểu số, SMOTE tạo ra các mẫu mới dựa trên các điểm gần nhất trong không gian đặc trưng.\n",
    "\n",
    "**3. Quy trình SMOTE:**\n",
    "\n",
    "Quy trình SMOTE bao gồm các bước sau:\n",
    "\n",
    "- **Bước 1: Chọn mẫu từ lớp thiểu số:**\n",
    "  Chọn ngẫu nhiên một mẫu từ lớp thiểu số.\n",
    "\n",
    "- **Bước 2: Tìm k hàng xóm gần nhất:**\n",
    "  Sử dụng phương pháp k-nearest neighbors (k-NN) để tìm k hàng xóm gần nhất của mẫu đã chọn.\n",
    "\n",
    "- **Bước 3: Tạo mẫu tổng hợp:**\n",
    "  - Chọn ngẫu nhiên một trong các hàng xóm gần nhất.\n",
    "  - Tạo một mẫu mới bằng cách lấy một điểm trên đoạn thẳng nối giữa mẫu đã chọn và hàng xóm đã chọn. Công thức như sau:\n",
    "    \\[\n",
    "    x_{\\text{new}} = x_1 + \\delta \\times (x_2 - x_1)\n",
    "    \\]\n",
    "    \\[\n",
    "    y_{\\text{new}} = y_1 + \\delta \\times (y_2 - y_1)\n",
    "    \\]\n",
    "    trong đó \\( \\delta \\) là một số ngẫu nhiên trong khoảng [0, 1].\n",
    "\n",
    "**4. Ưu điểm của SMOTE:**\n",
    "\n",
    "- **Cải thiện hiệu suất mô hình:** Bằng cách tăng số lượng mẫu thiểu số, SMOTE giúp mô hình học máy không bị thiên vị và cải thiện khả năng phân loại lớp thiểu số.\n",
    "- **Giảm hiện tượng overfitting:** So với việc nhân bản các mẫu thiểu số, SMOTE tạo ra các mẫu tổng hợp mới, giúp mô hình không bị overfitting do các mẫu lặp lại.\n",
    "\n",
    "**5. Nhược điểm của SMOTE:**\n",
    "\n",
    "- **Giới thiệu nhiễu:** Nếu dữ liệu thiểu số có sự phân tán lớn hoặc có nhiễu, SMOTE có thể tạo ra các mẫu tổng hợp không chính xác hoặc không hữu ích.\n",
    "- **Tăng kích thước dữ liệu:** SMOTE làm tăng số lượng mẫu, có thể dẫn đến tăng thời gian huấn luyện và yêu cầu bộ nhớ.\n",
    "\n",
    "**6. Ứng dụng và triển khai:**\n",
    "\n",
    "SMOTE thường được sử dụng trong các bài toán phân loại, đặc biệt là khi đối mặt với dữ liệu không cân bằng. Có nhiều thư viện hỗ trợ SMOTE, trong đó `imbalanced-learn` là một trong những thư viện phổ biến nhất trong Python.\n",
    "\n",
    "Ví dụ triển khai SMOTE trong Python:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tạo dữ liệu mẫu\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "# Kiểm tra tỷ lệ lớp ban đầu\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "\n",
    "# Áp dụng SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Kiểm tra tỷ lệ lớp sau khi áp dụng SMOTE\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "# Plot dữ liệu\n",
    "plt.scatter(X_res[:, 0], X_res[:, 1], c=y_res, alpha=0.6, edgecolor='k')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**7. Các biến thể của SMOTE:**\n",
    "\n",
    "Có nhiều biến thể của SMOTE nhằm cải thiện hiệu suất và giảm thiểu nhược điểm của SMOTE gốc:\n",
    "- **Borderline-SMOTE:** Tạo mẫu tổng hợp chỉ từ các mẫu gần ranh giới giữa các lớp.\n",
    "- **ADASYN (Adaptive Synthetic Sampling):** Tạo nhiều mẫu tổng hợp hơn cho các vùng có mật độ thấp trong lớp thiểu số.\n",
    "- **SMOTE-ENN:** Kết hợp SMOTE với kỹ thuật loại bỏ mẫu bằng phương pháp Edited Nearest Neighbors (ENN) để loại bỏ các mẫu nhiễu sau khi áp dụng SMOTE.\n",
    "\n",
    "### Tổng kết:\n",
    "SMOTE là một kỹ thuật mạnh mẽ và phổ biến để xử lý vấn đề mất cân bằng lớp trong học máy. Bằng cách tạo ra các mẫu tổng hợp từ lớp thiểu số, SMOTE giúp cải thiện hiệu suất của các mô hình phân loại, đặc biệt là trong các bài toán mà lớp thiểu số rất ít so với lớp đa số. Tuy nhiên, việc áp dụng SMOTE cần được thực hiện cẩn thận để tránh việc giới thiệu nhiễu và tăng kích thước dữ liệu không cần thiết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL mau moi nhan: Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"E:/IAD/INTERN/01_diabetes/data/diabetes.csv\")\n",
    "print(f\"SL mau moi nhan: {df['Outcome'].value_counts()}\")\n",
    "# => nhìn vào kết quả ta thấy dữ liệu chưa cân bằng cho mỗi nhãn, cần thực hiện cân bằng dữ liệu bằng kĩ thuật SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 500, 0: 500})\n"
     ]
    }
   ],
   "source": [
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "# print(x.shape, y.shape)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_res, y_res = smote.fit_resample(x, y)\n",
    "print(Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.75\n",
      "precision = 0.7428571428571429\n",
      "recall = 0.75\n",
      "f1 = 0.7572815533980582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'accuracy = {accuracy}')\n",
    "precision = precision_score(y_test, pred)\n",
    "print(f'precision = {precision}')\n",
    "recall = recall_score(y_test, pred)\n",
    "print(f'recall = {accuracy}')\n",
    "f1 = f1_score(y_test, pred)\n",
    "print(f'f1 = {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
