{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxrl_4IhbSSd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVA4qiNI6Xvm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import optimizers, Sequential\n",
        "from keras.models import Model\n",
        "#from keras.utils import plot_model\n",
        "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "import numpy as np\n",
        "from numpy import arange, sin, pi, random\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.integrate as integrate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "np.random.seed(1234)  \n",
        "PYTHONHASHSEED = 0\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOiH3SauAUbV"
      },
      "source": [
        "#Import Data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4HWVBN16Xvv"
      },
      "outputs": [],
      "source": [
        "data = np.load('/content/drive/MyDrive/Forecasting_Anomaly_Detection_Auto_LSTM-master/Anomaly_detection/scada1_1.npz')\n",
        "lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "#     print(data[item])\n",
        "X_train = data['training']\n",
        "X_test = data['test']\n",
        "idx_anomaly_test = data['idx_anomaly_test']\n",
        "normal_test_data = X_test[~idx_anomaly_test]\n",
        "anomalous_test_data = X_test[idx_anomaly_test]\n",
        "test_index = data['idx_anomaly_test']\n",
        "#print(X_test.shape)\n",
        "y_test = [1]*len(data['t_test'])\n",
        "for i in test_index:\n",
        "  y_test[i-1] = -1\n",
        "#print(y_test)\n",
        "#Split X_train and X_test according to the ratio of 80:20\n",
        "X_train = X_train[0:40192]\n",
        "X_test = X_test[0:10048]\n",
        "y_test = y_test[0:10048]\n",
        "#Reshape the input data to fit LSTM model\n",
        "X_train = np.reshape(X_train, (2512,16,16))\n",
        "X_test = np.reshape(X_test, (628,16,16))\n",
        "sequence_length =16\n",
        "DATA_SPLIT_PCT = 0.2\n",
        "SEED = 123 #used to help randomly select the data points\n",
        "batch_size = 50\n",
        "epochs = 30\n",
        "X_train_X, X_valid = train_test_split(X_train, test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
        "timesteps =  16 # equal to the sequence_length\n",
        "n_features =  16\n",
        "print(X_train_X.shape)\n",
        "print(X_valid.shape) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiKbYw_uEoCF"
      },
      "source": [
        "#LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f68CHy1G6Xv5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "results = {}\n",
        "for num_cells in [64]:\n",
        "    for lr in [1e-3]:\n",
        "            print('Running with', num_cells, \n",
        "                  'LSTM cells'\n",
        "                  'and learning rate =', lr, '...')\n",
        "\n",
        "            # build network\n",
        "            lstm_autoencoder = Sequential()\n",
        "            # Encoder\n",
        "            lstm_autoencoder.add(LSTM(100, activation='relu', input_shape=(timesteps, n_features), return_sequences=True))\n",
        "            lstm_autoencoder.add(LSTM(25, activation='relu', return_sequences=False))\n",
        "            lstm_autoencoder.add(RepeatVector(timesteps))\n",
        "            # Decoder\n",
        "            lstm_autoencoder.add(LSTM(25, activation='relu', return_sequences=True))\n",
        "            lstm_autoencoder.add(LSTM(100, activation='relu', return_sequences=True)) \n",
        "            lstm_autoencoder.add(TimeDistributed(Dense(n_features)))\n",
        "            # lstm_autoencoder.add(tf.keras.layers.Flatten())\n",
        "            lstm_autoencoder.summary()\n",
        "            adam = tf.optimizers.Adam(lr)\n",
        "            lstm_autoencoder.compile(loss='mse', optimizer=adam)\n",
        "            cp = ModelCheckpoint(filepath=\"lstm_autoencoder_classifier.h5\",\n",
        "                               save_best_only=True,\n",
        "                               verbose=0)\n",
        "            tb = TensorBoard(log_dir='./logs',\n",
        "                histogram_freq=0,\n",
        "                write_graph=True,\n",
        "                write_images=True)\n",
        "            lstm_autoencoder_history = lstm_autoencoder.fit(X_train, X_train, \n",
        "                                                epochs=epochs, \n",
        "                                                batch_size=batch_size, \n",
        "                                                validation_data=(X_valid, X_valid),\n",
        "                                                verbose=2, callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')]).history\n",
        "            print(\"Predicting...\")\n",
        "            predicted_train = lstm_autoencoder.predict(X_train)\n",
        "            predicted = lstm_autoencoder.predict(X_test)         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrCvj0UTFfI4"
      },
      "source": [
        "#Anomaly Detection using OCSVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHQb7VdL9nL0"
      },
      "outputs": [],
      "source": [
        "e = X_train - predicted_train\n",
        "nsamples, nx, ny = e.shape\n",
        "d2_e = e.reshape((nsamples*nx,ny))\n",
        "X_train1 = d2_e\n",
        "X_test1 = X_test.reshape(10048,16)\n",
        "from sklearn.svm import OneClassSVM\n",
        "model = OneClassSVM(kernel = 'rbf', gamma = 0.07, nu = 0.003).fit(X_train1)\n",
        "# model = OneClassSVM(kernel = 'rbf', gamma = 0.008, nu = 0.001).fit(X_train1)\n",
        "##{'gamma': 0.001, 'kernel': 'rbf', 'nu': 0.001}\n",
        "y_predict = model.predict(X_test1)\n",
        "precision = precision_score(y_test, y_predict)\n",
        "recall    = recall_score(y_test, y_predict)\n",
        "accuracy = accuracy_score(y_test, y_predict)\n",
        "f1 = f1_score(y_test, y_predict)\n",
        "print ('Accuracy : ', accuracy)\n",
        "print ('Precision : ', precision)\n",
        "print ('Recall: ', recall)\n",
        "print ('F1_score: ', f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dSXAYad5He3"
      },
      "outputs": [],
      "source": [
        "# for i in range(1,10):\n",
        "#   for j in range(1,10):\n",
        "#     model = OneClassSVM(kernel = 'rbf', gamma = 0.01*i, nu = 0.001*j).fit(X_train1)\n",
        "#     y_predict = model.predict(X_test1)\n",
        "#     precision = precision_score(y_test, y_predict)\n",
        "#     recall    = recall_score(y_test, y_predict)\n",
        "#     f1 = f1_score(y_test, y_predict)\n",
        "#     print(i)\n",
        "#     print(j)\n",
        "#     print ('Precision : ', precision)\n",
        "#     print ('Recall: ', recall)\n",
        "#     print ('F1_score: ', f1)\n",
        "#7/3\n",
        "#Precision :  0.8470223599734337\n",
        "#Recall:  0.9627579265223956\n",
        "#F1_score:  0.9011894947591567"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0DHFCMywmg7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "y_score = model.decision_function(X_test1)\n",
        "display = PrecisionRecallDisplay.from_predictions(y_test, y_score, name=\"LinearSVC\")\n",
        "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA75YOjQK9pY"
      },
      "outputs": [],
      "source": [
        "# for i in range(1,10):\n",
        "#   for j in range(1,9):\n",
        "#     model = OneClassSVM(kernel = 'rbf',degree = j, gamma = 0.001*i, nu = 0.002*i).fit(X_train1)\n",
        "#     y_predict = model.predict(X_test1)\n",
        "#     f1 = f1_score(y_test, y_predict)\n",
        "#     print ('F1_score: ', f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtrXnUY4x5jx"
      },
      "outputs": [],
      "source": [
        "# predicted_train = lstm_autoencoder.predict(X_train)\n",
        "# predicted = lstm_autoencoder.predict(X_test)\n",
        "# mse = np.mean(np.power(flatten(X_test) - flatten(predicted), 2), axis=1)\n",
        "# mse_train = np.mean(np.power(flatten(X_train) - flatten(predicted_train), 2), axis=1)\n",
        "# params = {'bandwidth': np.linspace(0, 0.5, 10)}\n",
        "# grid = GridSearchCV(KernelDensity(), params, cv = 20)\n",
        "# grid.fit(mse_train[:, None])\n",
        "# h=grid.best_estimator_.bandwidth2\n",
        "# tau=FindThreshold(mse_train,h,0.56)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emAHIF8rJdCl"
      },
      "source": [
        "#Model Explantation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHbN0Rtj5ukD"
      },
      "outputs": [],
      "source": [
        "lstm_autoencoder1 = Sequential()\n",
        "# Encoder\n",
        "lstm_autoencoder1.add(LSTM(100, activation='relu', input_shape=(timesteps, n_features), return_sequences=True))\n",
        "lstm_autoencoder1.add(LSTM(25, activation='relu', return_sequences=False))\n",
        "lstm_autoencoder1.add(RepeatVector(timesteps))\n",
        "# Decoder\n",
        "lstm_autoencoder1.add(LSTM(25, activation='relu', return_sequences=True))\n",
        "lstm_autoencoder1.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "lstm_autoencoder1.add(TimeDistributed(Dense(n_features)))\n",
        "lstm_autoencoder1.add(tf.keras.layers.Flatten())\n",
        "lstm_autoencoder1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kh8HV2n6wvv"
      },
      "outputs": [],
      "source": [
        "#transfer model\n",
        "lstm_autoencoder1.layers[0].set_weights(lstm_autoencoder.layers[0].get_weights())\n",
        "lstm_autoencoder1.layers[1].set_weights(lstm_autoencoder.layers[1].get_weights())\n",
        "lstm_autoencoder1.layers[2].set_weights(lstm_autoencoder.layers[2].get_weights())\n",
        "lstm_autoencoder1.layers[3].set_weights(lstm_autoencoder.layers[3].get_weights())\n",
        "lstm_autoencoder1.layers[4].set_weights(lstm_autoencoder.layers[4].get_weights())\n",
        "lstm_autoencoder1.layers[5].set_weights(lstm_autoencoder.layers[5].get_weights())\n",
        "predicted_train1 = lstm_autoencoder1.predict(X_train)\n",
        "# print(predicted_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVmPPaDOxIs7"
      },
      "outputs": [],
      "source": [
        "!pip  install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7an_n5B-6Xv8"
      },
      "outputs": [],
      "source": [
        "import shap \n",
        "# X_train2 = X_train[0:400]\n",
        "X_train2 = X_train[:]\n",
        "explainer = shap.GradientExplainer(lstm_autoencoder1, X_train2)\n",
        "X_test_2 = X_test[0:16]\n",
        "shap_values  = explainer.shap_values(X_test_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ubaz96kNrzG"
      },
      "outputs": [],
      "source": [
        "shap.initjs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E54CmARJN2-X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "features = ['address','function','length','setpoint','gain','reset rate','deadband','cycle time','rate','system mode','control scheme','pump','solenoid','pressure measurement','crc rate','command reponse']\n",
        "shap_values_2D = shap_values[0].reshape(-1,16)\n",
        "X_test_2D = X_test_2.reshape(-1,16)\n",
        "x_test_2d = pd.DataFrame(data=X_test_2D, columns = features)\n",
        "# x_test_2d.corr()\n",
        "shap.summary_plot(shap_values_2D, x_test_2d)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM-OCSVM-SHAP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
