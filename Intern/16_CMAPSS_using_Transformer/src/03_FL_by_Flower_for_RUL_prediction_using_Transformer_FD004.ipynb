{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnYweYq7MAx_"
      },
      "source": [
        "# Part I. RUL prediction using Transformer model (Centralize model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkndtwvEMAyB"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9u9NGr2MAyB",
        "outputId": "29244025-6832-4664-ba1b-7db0e3af4975"
      },
      "outputs": [],
      "source": [
        "# When run code on Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "print(f'IN_COLAB: {IN_COLAB}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Bwn09CMAyD",
        "outputId": "6c8b1ae9-10c9-4949-e2ef-5508f06bf4d6"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3A85IsxNMAyD"
      },
      "outputs": [],
      "source": [
        "# Off log duplicate messages\n",
        "import os\n",
        "os.environ[\"RAY_DEDUP_LOGS\"] = \"0\"\n",
        "\n",
        "# Off warning messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# import pyinspect as pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HPY8OhXWMAyD"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import Metrics, Context\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import run_simulation\n",
        "# from flwr_datasets import FederatedDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVkgjO0FMAyE",
        "outputId": "83016b96-aa2a-4bf8-aa1c-42a6ad9ea3bb"
      },
      "outputs": [],
      "source": [
        "# Check GPU if available else CPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
        "disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjJsJCeIMAyE"
      },
      "source": [
        "# Building Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hTrlkOGbMAyE"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, nhead, num_layers, dim_feedforward, dropout):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.input_embedding = nn.Linear(input_dim, d_model)\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, 5000, d_model))\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc_out = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src_emb = self.input_embedding(src) + self.positional_encoding[:, :src.size(1), :]\n",
        "        src_emb = src_emb.permute(1, 0, 2)\n",
        "        transformer_out = self.transformer(src_emb, src_emb)\n",
        "        output = self.fc_out(transformer_out[-1, :, :])\n",
        "        return output.squeeze(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MofOJ5kcMAyF"
      },
      "source": [
        "# Building Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vOZ_DGvDMAyF"
      },
      "outputs": [],
      "source": [
        "class CMAPSSLoaderDataset(Dataset):\n",
        "    def __init__(self, data, sequence_length):\n",
        "        self.data = data\n",
        "        self.sequence_length = sequence_length\n",
        "        self.sequences = []\n",
        "        self.targets = []\n",
        "\n",
        "        grouped = data.groupby('ID Engine')\n",
        "        for _, group in grouped:\n",
        "            values = group.drop(['ID Engine', 'Cycle', 'Setting 1', 'Setting 2', 'Setting 3','Remaining RUL'], axis=1).values\n",
        "            rul_values = group['Remaining RUL'].values\n",
        "\n",
        "            for i in range(len(values) - sequence_length + 1):\n",
        "                self.sequences.append(values[i:i + sequence_length])\n",
        "                self.targets.append(rul_values[i + sequence_length - 1])\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            torch.tensor(self.sequences[idx], dtype=torch.float32),\n",
        "            torch.tensor(self.targets[idx], dtype=torch.float32),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUlltooqMAyF"
      },
      "source": [
        "# Define parameters for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0TC27RxyMAyF"
      },
      "outputs": [],
      "source": [
        "# Transformer parameters\n",
        "input_dim = 21\n",
        "d_model = 64\n",
        "nhead = 4\n",
        "num_layers = 2\n",
        "dim_feedforward = 256\n",
        "dropout = 0.1\n",
        "learning_rate = 1e-3\n",
        "verbose=False\n",
        "\n",
        "# Dataloader parameters\n",
        "sequence_length = 30\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 128\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLLW79nlMAyG"
      },
      "source": [
        "# Define training/test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M_DmheohMAyG"
      },
      "outputs": [],
      "source": [
        "def train_model(model, client_loader_train, client_loader_validation: None, epochs: int, learning_rate: int, verbose=False):\n",
        "    model = model.to(DEVICE)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in client_loader_train:\n",
        "            seq, target = batch\n",
        "            seq, target = seq.to(DEVICE), target.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(seq)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        val_loss = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_loader_validation:\n",
        "                seq, target = batch\n",
        "                seq, target = seq.to(DEVICE), target.to(DEVICE)\n",
        "                output = model(seq)\n",
        "                loss = criterion(output, target)\n",
        "                val_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(client_loader_train)}, Validation Loss: {val_loss/len(client_loader_validation)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wAImKs32MAyG"
      },
      "outputs": [],
      "source": [
        "def test_model(model, client_loader_validation, return_actual_rul=False, show_fig=False):\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    samples, targets = next(iter(client_loader_validation))\n",
        "    samples, targets = samples.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in client_loader_validation:\n",
        "            samples, targets = batch\n",
        "            samples, targets = samples.to(DEVICE), targets.to(DEVICE)\n",
        "            predictions = model(samples)\n",
        "            val_loss += criterion(predictions, targets).item()\n",
        "    return val_loss/len(client_loader_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUo0_klUMAyG"
      },
      "source": [
        "# Define prediction functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poU0s6olMAyG"
      },
      "source": [
        "### Prediction on a batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BpY8ZLQjMAyG"
      },
      "outputs": [],
      "source": [
        "def predict_on_batch(model, batch_loader, return_actual_rul=False, show_fig=False):\n",
        "    criterion = nn.MSELoss()\n",
        "    samples, targets = batch_loader\n",
        "    samples, targets = samples.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "        predictions = model(samples)\n",
        "    loss = criterion(predictions, targets)\n",
        "\n",
        "    if return_actual_rul:\n",
        "        samples = samples.cpu()\n",
        "        targets = targets.cpu()\n",
        "\n",
        "        rul_min = scaler.data_min_[-1]\n",
        "        rul_max = scaler.data_max_[-1]\n",
        "\n",
        "        predictions = predictions.cpu()\n",
        "        actual_predictions = predictions.numpy() * (rul_max - rul_min) + rul_min\n",
        "        actual_targets = targets.numpy() * (rul_max - rul_min) + rul_min\n",
        "\n",
        "        if show_fig:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(range(len(actual_predictions)), actual_predictions, label=\"Predicted RUL\", marker='o', linestyle='-')\n",
        "            plt.plot(range(len(actual_targets)), actual_targets, label=\"Actual RUL\", marker='x', linestyle='--')\n",
        "            plt.title(\"Comparison of Predicted and Actual RUL\")\n",
        "            plt.xlabel(\"Sample Index\")\n",
        "            plt.ylabel(\"Remaining Useful Life (RUL)\")\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "        return loss, actual_predictions, actual_targets\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcUDCjUJMAyG"
      },
      "source": [
        "### Prediction on a sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fGf0T_-RMAyH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg8XtAIsMAyH"
      },
      "source": [
        "# File paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NoA5alN6MAyH"
      },
      "outputs": [],
      "source": [
        "# train_path = \"../data/train_FD004.txt\"\n",
        "# test_path = \"../data/test_FD004.txt\"\n",
        "# rul_path = \"../data/RUL_FD004.txt\"\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/RUL_prediction_using_Transformer/train_FD004.txt\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/RUL_prediction_using_Transformer/test_FD004.txt\"\n",
        "rul_path = \"/content/drive/MyDrive/Colab Notebooks/RUL_prediction_using_Transformer/RUL_FD004.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp3n8jv4MAyH"
      },
      "source": [
        "# Calculate RUL for train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Vov3xOdjMAyH"
      },
      "outputs": [],
      "source": [
        "# Initialization columns\n",
        "index_names = ['ID Engine', 'Cycle']\n",
        "setting_names = ['Setting 1', 'Setting 2', 'Setting 3']\n",
        "sensor_names = ['Sensor {}'.format(i) for i in range(1, 22)]\n",
        "column_names = index_names + setting_names + sensor_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g4Z2gsHhMAyH"
      },
      "outputs": [],
      "source": [
        "# Load trainset\n",
        "train = pd.read_csv(train_path, sep=' ', header=None)\n",
        "train.drop([26, 27], axis=1, inplace=True)\n",
        "train.columns = column_names\n",
        "\n",
        "train['Remaining RUL'] = ''\n",
        "# train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7SrC16fMAyH",
        "outputId": "102369b0-610b-44bc-feff-26f024af4601"
      },
      "outputs": [],
      "source": [
        "# Calculate the remaining RUL for each engine\n",
        "max_cycle = train.groupby('ID Engine').count()\n",
        "for idx in range(len(train)):\n",
        "    train.loc[idx, 'Remaining RUL'] = max_cycle.loc[train.loc[idx, 'ID Engine'], 'Cycle']\n",
        "train['Remaining RUL'] = train['Remaining RUL'] - train['Cycle']\n",
        "\n",
        "print(f\"trainset shape: {train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3qppLFRiMAyI",
        "outputId": "c9b3bd07-438d-4f7b-bb69-3111085697c5"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhXW7sjEMAyI"
      },
      "source": [
        "# Load RUL set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzSU4pRhMAyI",
        "outputId": "963152c3-afca-402d-a7fc-c3ef27793cd2"
      },
      "outputs": [],
      "source": [
        "rul = pd.read_csv(rul_path, sep=' ', header=None)\n",
        "rul.drop(rul.columns[1], axis=1, inplace=True)\n",
        "rul.columns = ['RUL']\n",
        "print(f'RUL shape: {rul.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prm8__JfMAyI"
      },
      "source": [
        "Tập RUL này là vòng đời còn lại của động cơ sau khi trải qua số lượng chu kỳ nhất định trong tập test (tương ứng)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fEYsXc7dMAyJ",
        "outputId": "ed4a9387-1459-45d4-d267-93cc17aa376a"
      },
      "outputs": [],
      "source": [
        "rul.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uqS8lkPMAyJ"
      },
      "source": [
        "# Calculate RUL for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1CugO7TMAyJ",
        "outputId": "ca91699b-8d09-4012-8f19-40f4bc23fdba"
      },
      "outputs": [],
      "source": [
        "# Load test set\n",
        "test = pd.read_csv(test_path, sep=' ', header=None)\n",
        "test.drop([26, 27], axis=1, inplace=True)\n",
        "test.columns = column_names\n",
        "\n",
        "test['Remaining RUL'] = ''\n",
        "# test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dTygyMtMAyJ",
        "outputId": "50229fc5-16d6-44d3-944f-c9ee9460f192"
      },
      "outputs": [],
      "source": [
        "max_cycle_test = test.groupby('ID Engine').count()\n",
        "\n",
        "for idx in range(len(test)):\n",
        "    test.loc[idx, 'Remaining RUL'] = rul.loc[test.loc[idx, 'ID Engine'] - 1, 'RUL'] + max_cycle_test.loc[test.loc[idx, 'ID Engine'], 'Cycle']\n",
        "test['Remaining RUL'] = test['Remaining RUL'] - test['Cycle']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rIVfgCQyMAyJ",
        "outputId": "32d9835b-970b-484d-b96b-d9b342a853ea"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj7dyHsdMAyK"
      },
      "source": [
        "# Standard data (for train and test set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU2HL_DdMAyK",
        "outputId": "94a078eb-069b-4c4e-f469-f90f3f75504e"
      },
      "outputs": [],
      "source": [
        "scaled_columns = train.columns[5:]\n",
        "scaler = MinMaxScaler()\n",
        "train[scaled_columns] = scaler.fit_transform(train[scaled_columns])\n",
        "test[scaled_columns] = scaler.fit_transform(test[scaled_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SuOOhTnTMAyK",
        "outputId": "3ff6a48e-9bf8-4577-a03c-1c9367ac68f1"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "grL9j-TBMAyP",
        "outputId": "42034762-a6e3-4866-e37f-d52c2dcf0d4f"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBBvfsbBMAyQ"
      },
      "source": [
        "# Load data into DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-fCRjrGMAyQ",
        "outputId": "cbbed570-193c-443a-f525-8619dc578c47"
      },
      "outputs": [],
      "source": [
        "data_train = CMAPSSLoaderDataset(data=train, sequence_length=sequence_length)\n",
        "# data_test = CMAPSSLoaderDataset(data=test, sequence_length=sequence_length)\n",
        "\n",
        "data_train, data_validation = train_test_split(data_train, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(data_validation, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mbFbgaGMAyQ",
        "outputId": "82e9bb6e-ed52-4329-ad5e-e808a8d0e97a"
      },
      "outputs": [],
      "source": [
        "data_train.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifKkIFWIMAyQ",
        "outputId": "06e024d8-87d2-461f-98d7-2b429886bacf"
      },
      "outputs": [],
      "source": [
        "data_validation.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8bBfTBdMAyR",
        "outputId": "870816a5-d39d-4c90-ba65-db01732dd6d8"
      },
      "outputs": [],
      "source": [
        "train_loader.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8eckzDgMAyR",
        "outputId": "5222057c-b007-4690-8898-8fa4634d9e97"
      },
      "outputs": [],
      "source": [
        "validation_loader.__len__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mg4QiLCMAyR"
      },
      "source": [
        "# Training centralize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "C68QobdXMAyR"
      },
      "outputs": [],
      "source": [
        "centralize_transformer_model = TransformerModel(\n",
        "    input_dim=input_dim,\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_layers=num_layers,\n",
        "    dim_feedforward=256,\n",
        "    dropout=dropout\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gSMS-WvMAyR",
        "outputId": "bf8f476c-e550-4689-9981-efd775147e08"
      },
      "outputs": [],
      "source": [
        "train_model(\n",
        "    model=centralize_transformer_model,\n",
        "    client_loader_train=train_loader,\n",
        "    client_loader_validation=validation_loader,\n",
        "    epochs=epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBpfPEUpMAyS"
      },
      "source": [
        "# Predict on batch (Centralize model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ovauxwPXMAyS",
        "outputId": "e9d0fcef-76a7-4cb9-face-55854d391db0"
      },
      "outputs": [],
      "source": [
        "batch_loader = next(iter(validation_loader))\n",
        "\n",
        "loss, _, _ = predict_on_batch(\n",
        "    model=centralize_transformer_model,\n",
        "    batch_loader=batch_loader,\n",
        "    return_actual_rul=True,\n",
        "    show_fig=True,\n",
        ")\n",
        "print(f'Loss on random batch: {loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V-hgj5JMAyS"
      },
      "source": [
        "# Part II. Setup Federated Learning with Flower for RUL prediction using Transformer model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbc5HTBUMAyS"
      },
      "source": [
        "### Define parameters for training FL with Flower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyFG0CdWMAyS",
        "outputId": "7bab51ee-877d-4905-9172-64746410c0f6"
      },
      "outputs": [],
      "source": [
        "num_clients = 10\n",
        "num_rounds = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFsCsOyIMAyS"
      },
      "source": [
        "### Split dataframe to 10 subframe for 10 client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5Bidza4aMAyT"
      },
      "outputs": [],
      "source": [
        "def split_dataset(dataset, num_clients):\n",
        "    \"\"\"\n",
        "    Chia dataset thành num_clients tập con đều nhau.\n",
        "    Args:\n",
        "        dataset: Dataset cần chia (torch.utils.data.Dataset).\n",
        "        num_clients: Số lượng tập con muốn tạo.\n",
        "    Returns:\n",
        "        List chứa các tập con của dataset.\n",
        "    \"\"\"\n",
        "    # Kích thước mỗi tập con\n",
        "    subset_size = len(dataset) // num_clients\n",
        "    sizes = [subset_size] * num_clients\n",
        "\n",
        "    # Chia phần dư (nếu tổng dataset không chia hết)\n",
        "    sizes[-1] += len(dataset) - sum(sizes)\n",
        "\n",
        "    # Tạo danh sách các tập con\n",
        "    subsets = random_split(dataset, sizes)\n",
        "    return subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qBZf6hxMAyT",
        "outputId": "d66be3eb-48a0-4426-abde-353ac3acf820"
      },
      "outputs": [],
      "source": [
        "# train.head()\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Aj5LJJsLMAyT"
      },
      "outputs": [],
      "source": [
        "data = CMAPSSLoaderDataset(train, sequence_length=sequence_length)\n",
        "train_data, validation_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "subset_trains = split_dataset(train_data, num_clients=num_clients)\n",
        "subset_validations = split_dataset(validation_data, num_clients=num_clients)\n",
        "\n",
        "client_loader_trains = [DataLoader(subset, batch_size=batch_size, shuffle=True) for subset in subset_trains]\n",
        "client_loader_validations = [DataLoader(subset, batch_size=batch_size, shuffle=True) for subset in subset_validations]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIjOv3DbMAyT",
        "outputId": "cfd8f5a1-d79e-47ad-abe6-073367c4e356"
      },
      "outputs": [],
      "source": [
        "for i, loader in enumerate(client_loader_trains):\n",
        "    print(f\"Client {i+1} will use a subset with {len(loader.dataset)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ot2zTq7MAyU",
        "outputId": "e008b100-7167-457e-a0ab-623a0717cfc8"
      },
      "outputs": [],
      "source": [
        "for i, loader in enumerate(client_loader_trains):\n",
        "    print(f\"Client {i+1} will use a subset with {len(loader.dataset)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP_GaPfnMAyU"
      },
      "source": [
        "### Update model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "M6PNtLhnMAyU"
      },
      "outputs": [],
      "source": [
        "def set_parameters(model, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(model.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(model) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in model.state_dict().items()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYLbAQn_MAyU"
      },
      "source": [
        "### Define the Flower ClientApp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "YvYWLdCKMAyU"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, model, client_loader_train, client_loader_validation):\n",
        "        self.model = model\n",
        "        self.trainloader = client_loader_train\n",
        "        self.valloader = client_loader_validation\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        train_model(\n",
        "            model=self.model,\n",
        "            client_loader_train=self.trainloader,\n",
        "            client_loader_validation=self.valloader,\n",
        "            epochs=1,\n",
        "            learning_rate=learning_rate,\n",
        "            verbose=False\n",
        "        )\n",
        "        return get_parameters(self.model), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        # loss, accuracy = test(self.model, self.valloader)\n",
        "        loss = test_model(\n",
        "            model=self.model,\n",
        "            client_loader_validation=self.valloader,\n",
        "            return_actual_rul=False,\n",
        "            show_fig=False\n",
        "        )\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(0.0)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "uySkMzDwMAyU"
      },
      "outputs": [],
      "source": [
        "def client_fn(context: Context) -> Client:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    model = TransformerModel(\n",
        "        input_dim=input_dim,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_layers=num_layers,\n",
        "        dim_feedforward=dim_feedforward,\n",
        "        dropout=0.1\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data partition\n",
        "    # Read the node_config to fetch data partition associated to this node\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    trainloader = client_loader_trains[partition_id]\n",
        "    valloader = client_loader_validations[partition_id]\n",
        "\n",
        "    # Create a single Flower client representing a single organization\n",
        "    # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
        "    # to convert it to a subclass of `flwr.client.Client`\n",
        "    return FlowerClient(model, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "# Create the ClientApp\n",
        "client = ClientApp(client_fn=client_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuIAxKzIMAyV"
      },
      "source": [
        "### Define the Flower ServerApp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "GYI9D2jeMAyV"
      },
      "outputs": [],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
        "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=10,  # Wait until all 10 clients are available\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "0huq_J3CMAyV"
      },
      "outputs": [],
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    \"\"\"Construct components that set the ServerApp behaviour.\n",
        "\n",
        "    You can use the settings in `context.run_config` to parameterize the\n",
        "    construction of all elements (e.g the strategy or the number of rounds)\n",
        "    wrapped in the returned ServerAppComponents object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Configure the server for 5 rounds of training\n",
        "    config = ServerConfig(num_rounds=50)\n",
        "\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create the ServerApp\n",
        "server = ServerApp(server_fn=server_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7kLDqq5MAyV"
      },
      "source": [
        "### Run the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "uIXCYtEJMAyV"
      },
      "outputs": [],
      "source": [
        "# Specify the resources each of your clients need\n",
        "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "\n",
        "# When running on GPU, assign an entire GPU for each client\n",
        "if DEVICE.type == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
        "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
        "    # and how to set up the `backend_config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa4Oj4OrMAyV",
        "outputId": "f1dd62fb-2894-477f-891e-2e8ce1ecbe4b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Run simulation\n",
        "    run_simulation(\n",
        "        server_app=server,\n",
        "        client_app=client,\n",
        "        num_supernodes=num_clients,\n",
        "        backend_config=backend_config\n",
        "    )\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Simulation interrupted by user.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bkndtwvEMAyB",
        "xjJsJCeIMAyE",
        "MofOJ5kcMAyF",
        "uUlltooqMAyF",
        "fLLW79nlMAyG",
        "HUo0_klUMAyG",
        "Fg8XtAIsMAyH",
        "Wp3n8jv4MAyH",
        "mhXW7sjEMAyI",
        "lj7dyHsdMAyK",
        "tBBvfsbBMAyQ",
        "eBpfPEUpMAyS"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
